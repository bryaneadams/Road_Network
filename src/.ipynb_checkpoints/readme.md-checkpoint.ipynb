{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T07:16:18.892637Z",
     "start_time": "2018-02-04T07:16:18.882802Z"
    }
   },
   "source": [
    "# 1 Hardware requirements\n",
    "\n",
    "**Training**\n",
    "\n",
    "- 6+ core modern CPU (Xeon, i7) for fast image pre-processing;\n",
    "- The models were trained on 2 * GeForce 1080 Ti;\n",
    "- Training time on my setup ~ **3 hours** for models with 8-bit images as inputs;\n",
    "- Disk space - 40GB should be more than enough;\n",
    "\n",
    "**Inference**\n",
    "\n",
    "- 6+ core modern CPU (Xeon, i7) for fast image pre-processing;\n",
    "- On 2 * GeForce 1080 Ti inference takes **3-5 minutes**;\n",
    "- Graph creation takes **5-10 minutes**;\n",
    "\n",
    "# 2 Preparing and launching the Docker environment\n",
    "\n",
    "**Clone the repository**\n",
    "\n",
    "`git clone https://github.com/snakers4/spacenet-three .`\n",
    "\n",
    "\n",
    "**This repository contains 2 Dockerfiles**\n",
    "- `/dockerfiles/Dockerfile` - this is the main Dockerfile which was used as environment to run the training and inference scripts\n",
    "- `/dockerfiles/Dockerfile2`- this is an additional backup Docker file with newer versions of the drivers and PyTorch, just in case\n",
    "\n",
    "**Build a Docker image**\n",
    "\n",
    "`\n",
    "cd dockerfiles\n",
    "docker build -t aveysov .\n",
    "`\n",
    "\n",
    "**Install the latest nvidia docker**\n",
    "\n",
    "Follow instructions from [here](https://github.com/NVIDIA/nvidia-docker).\n",
    "Please prefer nvidia-docker2 for more stable performance.\n",
    "\n",
    "\n",
    "To test all works fine run:\n",
    "\n",
    "\n",
    "`docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi`\n",
    "\n",
    "**(IMPORTANT) Run docker container (IMPORTANT)**\n",
    "\n",
    "Unless you use this exact command (with --shm-size flag) (you can change ports and mounted volumes, of course), then the PyTorch generators **WILL NOT WORK**. \n",
    "\n",
    "\n",
    "- nvidia-docker 2: `docker run --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=all -it -v /path/to/cloned/repository:/home/keras/notebook -p 8888:8888 -p 6006:6006  --shm-size 8G aveysov`\n",
    "- nvidia-docker: `nvidia-docker -it -v /path/to/cloned/repository:/home/keras/notebook -p 8888:8888 -p 6006:6006  --shm-size 8G aveysov`\n",
    "\n",
    "**Installing project specific software**\n",
    "\n",
    "1. Exec into the docker machine via `docker exec -it --user root YOUR_CONTAINER_ID /bin/bash`\n",
    "2. Run these scripts one after another\n",
    "```\n",
    "conda install -y -c conda-forge cython\n",
    "conda install -y -c conda-forge rasterio\n",
    "conda install -y -c conda-forge libgdal\n",
    "conda install -y -c conda-forge gdal\n",
    "conda install -y -c conda-forge scikit-image\n",
    "conda install -y -c conda-forge pyproj\n",
    "conda install -y -c conda-forge geopandas\n",
    "conda install -y -c conda-forge tqdm\n",
    "conda install -y -c conda-forge shapely=1.5.16\n",
    "conda install -y -c conda-forge scipy\n",
    "conda install -y -c conda-forge networkx=1.11\n",
    "conda install -y -c conda-forge fiona\n",
    "pip3 install utm\n",
    "pip3 install osmnx==0.5.1\n",
    "```\n",
    "3. Run these scripts one after another\n",
    "```\n",
    "pip3 install numba\n",
    "conda install -y -c conda-forge scikit-image\n",
    "```\n",
    "\n",
    "Steps 2-3 are to ensure compatibility with legacy software from APLS [repository](https://github.com/CosmiQ/apls).\n",
    "An alternative to that - is to use pip's requirements.txt in the same order.\n",
    "These steps are required to run 8-bit mask creation step from APLS repository and mask creation step.\n",
    "If you will be trying to re-do this step - reserve 5-6 hours for experiments.\n",
    "\n",
    "**To start the stopped container**\n",
    "\n",
    "\n",
    "`docker start -i YOUR_CONTAINER_ID`\n",
    "\n",
    "\n",
    "# 3 Preparing the data and the machine for running scripts\n",
    "\n",
    "- Ssh into the docker container via `docker exec -it YOUR_CONTAINER_ID`\n",
    "- Cd to the root folder of thre repo\n",
    "- Dowload the data into `data/`\n",
    "- Run these commands:\n",
    "    - `mkdir src/weights`\n",
    "    - `mkdir src/tb_logs`\n",
    "    - `cd scripts` \n",
    "    - `python3 create_binary_masks.py` \n",
    "    - `python3 create_8bit_test_images.py` \n",
    "    \n",
    "    \n",
    "After all of your manipulations your directory should look like:\n",
    "\n",
    "```\n",
    "├── README.md          <- The top-level README for developers using this project.\n",
    "├── data\n",
    "│   ├── AOI_2_Vegas_Roads_Test_Public         <- Test set for each city\n",
    "│   └── AOI_2_Vegas_Roads_Train               <- Train set for each city\n",
    "│       ├─ geojson\n",
    "│       ├─ summaryData\n",
    "│       ├─ MUL\n",
    "│       ├─ RGB-PanSharpen\n",
    "│       ├─ PAN\n",
    "│       ├─ MUL-PanSharpen\n",
    "│       ├─ MUL-PanSharpen_8bit\n",
    "│       ├─ RGB-PanSharpen_8bit\n",
    "│       ├─ PAN_8bit\n",
    "│       ├─ MUL_8bit\n",
    "│       ├─ MUL-PanSharpen_mask\n",
    "│       ├─ RGB-PanSharpen_mask\n",
    "│       ├─ PAN_mask\n",
    "│       ├─ MUL_mask\n",
    "│       └─ RGB-PanSharpen_mask\n",
    "│   │\n",
    "│   ...\n",
    "│   │\n",
    "│   ├── AOI_5_Khartoum_Roads_Test_Public      <- Test set for each city\n",
    "│   └── AOI_5_Khartoum_Roads_Train            <- Train set for each city\n",
    "│\n",
    "├── dockerfiles                               <- A folder with Dockerfiles\n",
    "│\n",
    "├── src                                       <- Source code\n",
    "│\n",
    "└── scripts                                   <- One-off preparation scripts\n",
    "```\n",
    "\n",
    "# 4 Training the model\n",
    "\n",
    "If all is ok, then use the following command to train the model\n",
    "\n",
    "- Ssh into the docker container via `docker exec -it YOUR_CONTAINER_ID`\n",
    "- Cd to the root folder of thre repo\n",
    "- `cd src`\n",
    "- optional - turn on tensorboard for monitoring progress `tensorboard --logdir='satellites_roads/src/tb_logs' --port=6006` via jupyter notebook console or via tmux + docker exec (model converges in 30-40 epochs)\n",
    "- then\n",
    "```\n",
    "echo 'python3 train_satellites.py \\\n",
    "\t--arch linknet34 --batch-size 6 \\\n",
    "\t--imsize 1280 --preset mul_ps_vegetation --augs True \\\n",
    "\t--workers 6 --epochs 40 --start-epoch 0 \\\n",
    "\t--seed 42 --print-freq 20 \\\n",
    "\t--lr 1e-3 --optimizer adam \\\n",
    "\t--tensorboard True --lognumber ln34_mul_ps_vegetation_aug_dice' > train.sh\n",
    "```\n",
    "- `sh train.sh`\n",
    "\n",
    "# 5 Predicting masks\n",
    "\n",
    "- Ssh into the docker container via `docker exec -it YOUR_CONTAINER_ID`\n",
    "- Cd to the root folder of thre repo\n",
    "- `cd src`\n",
    "- then\n",
    "``` \n",
    "echo 'python3 train_satellites.py\\\n",
    "\t--arch linknet34 --batch-size 12\\\n",
    "\t--imsize 1312 --preset mul_ps_vegetation --augs True\\\n",
    "\t--workers 6 --epochs 50 --start-epoch 0\\\n",
    "\t--seed 42 --print-freq 10\\\n",
    "\t--lr 1e-3 --optimizer adam\\\n",
    "\t--lognumber norm_ln34_mul_ps_vegetation_aug_dice_predict\\\n",
    "\t--predict --resume weights/norm_ln34_mul_ps_vegetation_aug_dice_best.pth.tar\\' > predict.sh\n",
    "```\n",
    "- `sh predict.sh`\n",
    "\n",
    "\n",
    "# 6 Creating graphs and submission files\n",
    "`cd` into `src` directory and execute `final_model_lstrs.py` script as follows:\n",
    "```\n",
    "docker exec -it YOUR_CONTAINER_ID sh -c \"cd path/to/src && python3 final_model_lstrs.py --folder norm_ln34_mul_ps_vegetation_aug_dice_predict\"\n",
    "```\n",
    "`folder` argument is for masks containing folder name, default is `norm_ln34_mul_ps_vegetation_aug_dice_predict`.\n",
    "Scipt saves a file called `norm_test.csv` into `../solutions` directory. The resulting file is used then as a submission file.\n",
    "\n",
    "# 7 Additional notes\n",
    "\n",
    "- You can run training and inference on the presets from `/src/presets.py`;\n",
    "- So the model can be evaluated on RGB-PS images and / or 8-channel images as well;\n",
    "- This script, for example will train an 8-channel model:\n",
    "```\n",
    "python3 train_satellites.py \\\n",
    "\t--arch linknet34 --batch-size 6 \\\n",
    "\t--imsize 1280 --preset mul_ps_vegetation --augs True \\\n",
    "\t--workers 6 --epochs 40 --start-epoch 0 \\\n",
    "\t--seed 42 --print-freq 20 \\\n",
    "\t--lr 1e-3 --optimizer adam \\\n",
    "\t--tensorboard True --lognumber ln34_mul_ps_vegetation_aug_dice\n",
    "```\n",
    "\n",
    "To train an 8-channel model you should also replace mean and std settings in the `src/SatellitesAugs.py`\n",
    "\n",
    "```\n",
    "# 8-channel settings\n",
    "# normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "#                                 std=[1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# 3 channel settings\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "```\n",
    "\n",
    "- 16-bit images are also supported:\n",
    "\n",
    "This snippet is commented in `src/SatellitesAugs.py`\n",
    "\n",
    "```\n",
    "# version compatible with 16-bit images\n",
    "\"\"\"  \n",
    "class ImgAugAugs(object):\n",
    "    def __call__(self,\n",
    "                 image):\n",
    "        global seed        \n",
    "        \n",
    "        # poor man's flipping\n",
    "        if seed%2==0:\n",
    "            image = np.fliplr(image)\n",
    "        elif seed%4==0:\n",
    "            image = np.fliplr(image)\n",
    "            image = np.flipud(image)\n",
    "        \n",
    "        # poor man's affine transformations\n",
    "        image = rotate(image,\n",
    "                     angle=seed,\n",
    "                     resize=False,\n",
    "                     clip=True,\n",
    "                     preserve_range=True)        \n",
    "\n",
    "        return image\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "- Also the following models are supported\n",
    "    - `unet11` (VGG11 + Unet)\n",
    "    - `linknet50` (ResNet50 + LinkNet, 3 layers)\n",
    "    - `linknet50_full` (ResNet50 + LinkNet, 4 layers)\n",
    "    - `linknext` (ResNext-101-32 + LinkNet, 4 layers)\n",
    "    \n",
    "- Also in the repo you can find scripts to generate wide masks (i.e. wide roads have varying width) and layered masks (paved / non-paved). There are scripts in the `src/SatellitesDataset.py` that support that. They basically just replace some paths; \n",
    "    \n",
    "# 8 Juputer notebooks\n",
    "\n",
    "Use these notebooks on your own risk!\n",
    "\n",
    "- `src/experiments.ipynb` - general debugging notebook with new models / generators / etc\n",
    "- `src/play_w_stuff.ipynb` - visualizing the solutions\n",
    "- `src/pipeline_experiments.ipynb`- some minor experiments with the graph creation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
